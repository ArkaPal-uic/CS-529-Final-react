{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BenignTraffic' 'MITM-ArpSpoofing' 'DDoS-ICMP_Fragmentation'\n",
      " 'Recon-OSScan' 'DNS_Spoofing' 'VulnerabilityScan' 'CommandInjection'\n",
      " 'BrowserHijacking']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# df = pd.read_csv(\"data\\part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")\n",
    "df = pd.read_csv(\"data/part-00157-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")\n",
    "df.rename(columns={'Magnitue': 'Magnitude'}, inplace=True)\n",
    "\n",
    "selected_labels = [\n",
    "    'BenignTraffic', 'BrowserHijacking', 'CommandInjection',\n",
    "    'DDoS-ICMP_Fragmentation', 'DNS_Spoofing', 'MITM-ArpSpoofing',\n",
    "    'Recon-OSScan', 'VulnerabilityScan'\n",
    "]\n",
    "\n",
    "df = df[df['label'].isin(selected_labels)]\n",
    "print(df['label'].unique())\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# Benign Traffic, Browser Hijacking, Command injection, DDoS-ICMP_Fragmentation, DNS Spoofing, MITM-ArpSpoofing, Recon-OSScan, Vulnerability scan.\n",
    "# Benign Traffic, Command injection, DDoS-ICMP_Fragmentation, DNS Spoofing, MITM-ArpSpoofing, Recon-OSScan, Vulnerability scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only 'label' and 'Magnitude' columns\n",
    "selected_data = df[['label', 'Magnitude']]\n",
    "\n",
    "# Group by 'label' and aggregate 'Magnitude' values into a list\n",
    "grouped_data = selected_data.groupby('label')['Magnitude'].agg(list).reset_index()\n",
    "\n",
    "# Select 1 in 4 entries for every label\n",
    "# selected_data_1_in_4 = grouped_data.groupby('label').apply(lambda x: x.iloc[::4]).reset_index(drop=True)\n",
    "\n",
    "# Save the selected data to a JSON file\n",
    "grouped_data.to_json('JSON/boxplot_data.json', orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'label' and convert each group to a list\n",
    "grouped_data = df.groupby('label')['Duration'].apply(list)\n",
    "\n",
    "# Convert the grouped data to a list of dictionaries\n",
    "data = [{'label': label, 'Duration': durations} for label, durations in grouped_data.items()]\n",
    "\n",
    "# Write the Python object to a file\n",
    "with open('JSON/violin-plot_Duration_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_columns = ['Duration', 'Tot size']\n",
    "# selected_data = df[selected_columns]\n",
    "# Save the selected data to a JSON file\n",
    "# selected_data.to_json('line-plot_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Duration', 'Tot size', 'label']\n",
    "grouped_data = df[selected_columns]\n",
    "\n",
    "# Group by 'label' and aggregate 'Duration' and 'Tot size' values into a list\n",
    "selected_data = grouped_data.groupby('label').agg(list).reset_index()\n",
    "\n",
    "# Convert DataFrame to JSON string\n",
    "json_str = selected_data.to_json(orient='records')\n",
    "\n",
    "# Parse JSON string to Python object\n",
    "data = json.loads(json_str)\n",
    "\n",
    "# Write pretty-printed JSON to file\n",
    "with open('JSON/scatter-plot_Size_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Step 1: Select numerical columns\n",
    "# numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# # Step 2: Calculate variance for each numerical column and select the top 10\n",
    "# top_variance_cols = df[numerical_cols].var().nlargest(10).index.tolist()\n",
    "\n",
    "# # Step 3: Print the top 10 columns with the highest numeric variance\n",
    "# print(\"Top 10 Columns with Highest Numeric Variance:\")\n",
    "# print(\", \".join(top_variance_cols))\n",
    "\n",
    "# # Step 4: Print mean, median, max, min, and standard deviation for each column across the top 10 labels\n",
    "# top_labels = df['label'].value_counts().nlargest(10).index.tolist()\n",
    "\n",
    "# result_data = {}\n",
    "\n",
    "# for col in top_variance_cols:\n",
    "#     result_data[col] = {}  # Initialize an empty dictionary for each column\n",
    "#     print(f\"\\nStatistics for '{col}' across the top 10 labels:\")\n",
    "#     for label in top_labels:\n",
    "#         values = df[df['label'] == label][col]\n",
    "#         # print(f\"{label}: Mean = {values.mean():.2f}, Median = {values.median():.2f}, Max = {values.max():.2f}, Min = {values.min():.2f}, Std Dev = {values.std():.2f}\")\n",
    "#         print(f\"{label}: Mean = {values.mean():.2f}\")\n",
    "#         result_data[col][label] = values.mean()\n",
    "\n",
    "# result_json = pd.DataFrame(result_data)\n",
    "# result_json.to_json(\"mean_data.json\", orient=\"index\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns with Highest Numeric Variance (excluding 'IAT' and 'Tot sum'):\n",
      "Header_Length, Covariance, Rate, Srate, Max, flow_duration, rst_count, Radius, Tot size, AVG\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Step 1: Select numerical columns\n",
    "# numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# # Remove \"IAT\" and \"Tot sum\" from the list of numerical columns\n",
    "# numerical_cols = [col for col in numerical_cols if col not in [\"IAT\", \"Tot sum\"]]\n",
    "\n",
    "# # Step 2: Calculate variance for each numerical column (excluding \"IAT\") and select the top 10\n",
    "# top_variance_cols = df[numerical_cols].var().nlargest(10).index.tolist()\n",
    "\n",
    "# # Step 3: Print the top 10 columns with the highest numeric variance\n",
    "# print(\"Top 10 Columns with Highest Numeric Variance (excluding 'IAT'):\")\n",
    "# print(\", \".join(top_variance_cols))\n",
    "\n",
    "# # Save the normalized data to a JSON file\n",
    "# normalized_data.to_json(\"spider-plot_normalized_data.json\", orient=\"index\", indent=4)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame, replace it with your actual DataFrame\n",
    "# df = ...\n",
    "\n",
    "# Step 1: Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Remove \"IAT\" and \"Tot sum\" from the list of numerical columns\n",
    "numerical_cols = [col for col in numerical_cols if col not in [\"IAT\", \"Tot sum\"]]\n",
    "\n",
    "# Step 2: Calculate variance for each numerical column (excluding \"IAT\") and select the top 10\n",
    "top_variance_cols = df[numerical_cols].var().nlargest(10).index.tolist()\n",
    "\n",
    "# Step 3: Print the top 10 columns with the highest numeric variance\n",
    "print(\"Top 10 Columns with Highest Numeric Variance (excluding 'IAT' and 'Tot sum'):\")\n",
    "print(\", \".join(top_variance_cols))\n",
    "\n",
    "# Save the normalized data to a JSON file\n",
    "df[top_variance_cols].to_json(\"JSON/spider-plot_normalized_data.json\", orient=\"index\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming df is your DataFrame, replace it with your actual DataFrame\n",
    "# df = ...\n",
    "\n",
    "selected_columns = ['label', 'Duration', 'Protocol Type']\n",
    "grouped_data = df[selected_columns]\n",
    "\n",
    "# Group by 'label' and aggregate 'Duration' and 'Protocol Type' values into lists\n",
    "selected_data = grouped_data.groupby('label').agg(list).reset_index()\n",
    "\n",
    "# Reduce the number of values for 'Duration' and 'Protocol Type' for every label\n",
    "selected_data['Duration'] = selected_data['Duration'].apply(lambda x: x[::3])\n",
    "selected_data['Protocol Type'] = selected_data['Protocol Type'].apply(lambda x: x[::3])\n",
    "\n",
    "# Convert DataFrame to JSON string\n",
    "json_str = selected_data.to_json(orient='records')\n",
    "\n",
    "# Parse JSON string to Python object\n",
    "data = json.loads(json_str)\n",
    "\n",
    "# Write pretty-printed JSON to file\n",
    "with open('JSON/line_plot_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
