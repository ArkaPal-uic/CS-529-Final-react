{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate',\n",
      "       'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
      "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
      "       'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count',\n",
      "       'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet',\n",
      "       'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
      "       'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number',\n",
      "       'Magnitude', 'Radius', 'Covariance', 'Variance', 'Weight', 'label'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "   flow_duration  Header_Length  Protocol Type  Duration        Rate  \\\n",
      "0       0.621457          71.28           6.00     64.00    1.029826   \n",
      "1       0.000000          54.00           6.00     64.00   23.345137   \n",
      "2       0.000000          54.00           6.00     64.00  195.657228   \n",
      "3       1.554891         148.50           6.00     64.00    3.122125   \n",
      "4       0.000000           2.14           1.16     69.73   35.679351   \n",
      "\n",
      "        Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  ...  \\\n",
      "0    1.029826    0.0              0.0              1.0              0.0  ...   \n",
      "1   23.345137    0.0              0.0              0.0              0.0  ...   \n",
      "2  195.657228    0.0              1.0              0.0              1.0  ...   \n",
      "3    3.122125    0.0              0.0              1.0              0.0  ...   \n",
      "4   35.679351    0.0              0.0              0.0              0.0  ...   \n",
      "\n",
      "         Std  Tot size           IAT  Number  Magnitude     Radius  \\\n",
      "0   0.000000     54.00  8.336568e+07     9.5  10.392305   0.000000   \n",
      "1   0.000000     54.00  8.295607e+07     9.5  10.392305   0.000000   \n",
      "2   0.000000     54.00  8.334390e+07     9.5  10.392305   0.000000   \n",
      "3   0.000000     54.00  8.336549e+07     9.5  10.392305   0.000000   \n",
      "4  10.246018     43.72  8.315004e+07     9.5   9.579713  14.503077   \n",
      "\n",
      "   Covariance  Variance  Weight                    label  \n",
      "0    0.000000      0.00  141.55  DDoS-SynonymousIP_Flood  \n",
      "1    0.000000      0.00  141.55            DoS-TCP_Flood  \n",
      "2    0.000000      0.00  141.55         DDoS-RSTFINFlood  \n",
      "3    0.000000      0.00  141.55  DDoS-SynonymousIP_Flood  \n",
      "4  592.844991      0.19  141.55          DDoS-ICMP_Flood  \n",
      "\n",
      "[5 rows x 47 columns]\n",
      "['DDoS-SynonymousIP_Flood' 'DoS-TCP_Flood' 'DDoS-RSTFINFlood'\n",
      " 'DDoS-ICMP_Flood' 'Mirai-udpplain' 'DDoS-SYN_Flood' 'DDoS-TCP_Flood'\n",
      " 'DDoS-PSHACK_Flood' 'Mirai-greeth_flood' 'Recon-HostDiscovery'\n",
      " 'DDoS-UDP_Flood' 'BenignTraffic' 'MITM-ArpSpoofing' 'DoS-UDP_Flood'\n",
      " 'DDoS-UDP_Fragmentation' 'DoS-HTTP_Flood' 'DoS-SYN_Flood'\n",
      " 'DDoS-ICMP_Fragmentation' 'Recon-OSScan' 'DNS_Spoofing'\n",
      " 'DDoS-ACK_Fragmentation' 'Mirai-greip_flood' 'Recon-PortScan'\n",
      " 'VulnerabilityScan' 'DDoS-HTTP_Flood' 'XSS' 'DDoS-SlowLoris'\n",
      " 'CommandInjection' 'Recon-PingSweep' 'BrowserHijacking'\n",
      " 'DictionaryBruteForce' 'SqlInjection' 'Uploading_Attack'\n",
      " 'Backdoor_Malware']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# df = pd.read_csv(\"data\\part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")\n",
    "df = pd.read_csv(\"data/part-00157-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")\n",
    "df.rename(columns={'Magnitue': 'Magnitude'}, inplace=True)\n",
    "print(df.columns)\n",
    "print(\"\\n\")\n",
    "print(df.head(5))\n",
    "print(df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only 'label' and 'Magnitude' columns\n",
    "selected_data = df[['label', 'Magnitude']]\n",
    "\n",
    "# Group by 'label' and aggregate 'Magnitude' values into a list\n",
    "grouped_data = selected_data.groupby('label')['Magnitude'].agg(list).reset_index()\n",
    "\n",
    "# Select 1 in 4 entries for every label\n",
    "selected_data_1_in_4 = grouped_data.groupby('label').apply(lambda x: x.iloc[::4]).reset_index(drop=True)\n",
    "\n",
    "# Save the selected data to a JSON file\n",
    "selected_data_1_in_4.to_json('boxplot_data.json', orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'label' and convert each group to a list\n",
    "grouped_data = df.groupby('label')['Duration'].apply(list)\n",
    "\n",
    "# Convert the grouped data to a list of dictionaries\n",
    "data = [{'label': label, 'Duration': durations} for label, durations in grouped_data.items()]\n",
    "\n",
    "# Write the Python object to a file\n",
    "with open('violin-plot_Duration_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['label', 'Tot size']\n",
    "selected_data = df[selected_columns]\n",
    "# Save the selected data to a JSON file\n",
    "selected_data.to_json('violin-plot_Size_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Tot size', 'ack_count']\n",
    "selected_data = df[selected_columns]\n",
    "# Save the selected data to a JSON file\n",
    "selected_data.to_json('scatter-plot_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Duration', 'Tot size']\n",
    "selected_data = df[selected_columns]\n",
    "# Save the selected data to a JSON file\n",
    "selected_data.to_json('line-plot_data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Duration', 'Tot size', 'label']\n",
    "grouped_data = df[selected_columns]\n",
    "\n",
    "# Group by 'label' and aggregate 'Duration' and 'Tot size' values into a list\n",
    "selected_data = grouped_data.groupby('label').agg(list)\n",
    "\n",
    "# Select 1 in 4 entries for every label\n",
    "selected_data = selected_data.apply(lambda x: x.iloc[::3]).reset_index()\n",
    "\n",
    "# Convert DataFrame to JSON string\n",
    "json_str = selected_data.to_json(orient='records')\n",
    "\n",
    "# Parse JSON string to Python object\n",
    "data = json.loads(json_str)\n",
    "\n",
    "# Write pretty-printed JSON to file\n",
    "with open('scatter-plot_Size_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns with Highest Numeric Variance:\n",
      "IAT, Header_Length, Covariance, Rate, Srate, Tot sum, Max, rst_count, flow_duration, Tot size\n",
      "\n",
      "Statistics for 'IAT' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 83152343.01\n",
      "DDoS-UDP_Flood: Mean = 83112939.89\n",
      "DDoS-TCP_Flood: Mean = 83052210.41\n",
      "DDoS-PSHACK_Flood: Mean = 83319668.59\n",
      "DDoS-RSTFINFlood: Mean = 83348220.32\n",
      "DDoS-SYN_Flood: Mean = 83097347.02\n",
      "DDoS-SynonymousIP_Flood: Mean = 83360158.18\n",
      "DoS-UDP_Flood: Mean = 83005684.48\n",
      "DoS-TCP_Flood: Mean = 82919880.57\n",
      "DoS-SYN_Flood: Mean = 82947407.27\n",
      "\n",
      "Statistics for 'Header_Length' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 481.55\n",
      "DDoS-UDP_Flood: Mean = 25199.86\n",
      "DDoS-TCP_Flood: Mean = 163.06\n",
      "DDoS-PSHACK_Flood: Mean = 151.13\n",
      "DDoS-RSTFINFlood: Mean = 702.42\n",
      "DDoS-SYN_Flood: Mean = 192.08\n",
      "DDoS-SynonymousIP_Flood: Mean = 276.46\n",
      "DoS-UDP_Flood: Mean = 19607.29\n",
      "DoS-TCP_Flood: Mean = 2655.89\n",
      "DoS-SYN_Flood: Mean = 2793.02\n",
      "\n",
      "Statistics for 'Covariance' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 685.57\n",
      "DDoS-UDP_Flood: Mean = 711.77\n",
      "DDoS-TCP_Flood: Mean = 648.21\n",
      "DDoS-PSHACK_Flood: Mean = 324.39\n",
      "DDoS-RSTFINFlood: Mean = 1063.01\n",
      "DDoS-SYN_Flood: Mean = 1178.55\n",
      "DDoS-SynonymousIP_Flood: Mean = 437.94\n",
      "DoS-UDP_Flood: Mean = 2372.76\n",
      "DoS-TCP_Flood: Mean = 2786.26\n",
      "DoS-SYN_Flood: Mean = 1892.22\n",
      "\n",
      "Statistics for 'Rate' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 11349.91\n",
      "DDoS-UDP_Flood: Mean = 17820.76\n",
      "DDoS-TCP_Flood: Mean = 6299.64\n",
      "DDoS-PSHACK_Flood: Mean = 5517.00\n",
      "DDoS-RSTFINFlood: Mean = 10264.08\n",
      "DDoS-SYN_Flood: Mean = 2718.07\n",
      "DDoS-SynonymousIP_Flood: Mean = 2358.36\n",
      "DoS-UDP_Flood: Mean = 19857.69\n",
      "DoS-TCP_Flood: Mean = 7696.65\n",
      "DoS-SYN_Flood: Mean = 1874.59\n",
      "\n",
      "Statistics for 'Srate' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 11349.91\n",
      "DDoS-UDP_Flood: Mean = 17820.76\n",
      "DDoS-TCP_Flood: Mean = 6299.64\n",
      "DDoS-PSHACK_Flood: Mean = 5517.00\n",
      "DDoS-RSTFINFlood: Mean = 10264.08\n",
      "DDoS-SYN_Flood: Mean = 2718.07\n",
      "DDoS-SynonymousIP_Flood: Mean = 2358.36\n",
      "DoS-UDP_Flood: Mean = 19857.69\n",
      "DoS-TCP_Flood: Mean = 7696.65\n",
      "DoS-SYN_Flood: Mean = 1874.59\n",
      "\n",
      "Statistics for 'Tot sum' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 450.40\n",
      "DDoS-UDP_Flood: Mean = 534.47\n",
      "DDoS-TCP_Flood: Mean = 599.80\n",
      "DDoS-PSHACK_Flood: Mean = 571.99\n",
      "DDoS-RSTFINFlood: Mean = 576.75\n",
      "DDoS-SYN_Flood: Mean = 592.95\n",
      "DDoS-SynonymousIP_Flood: Mean = 573.48\n",
      "DoS-UDP_Flood: Mean = 829.28\n",
      "DoS-TCP_Flood: Mean = 599.39\n",
      "DoS-SYN_Flood: Mean = 593.50\n",
      "\n",
      "Statistics for 'Max' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 46.03\n",
      "DDoS-UDP_Flood: Mean = 55.08\n",
      "DDoS-TCP_Flood: Mean = 60.90\n",
      "DDoS-PSHACK_Flood: Mean = 56.90\n",
      "DDoS-RSTFINFlood: Mean = 59.03\n",
      "DDoS-SYN_Flood: Mean = 61.58\n",
      "DDoS-SynonymousIP_Flood: Mean = 57.32\n",
      "DoS-UDP_Flood: Mean = 91.24\n",
      "DoS-TCP_Flood: Mean = 67.76\n",
      "DoS-SYN_Flood: Mean = 66.63\n",
      "\n",
      "Statistics for 'rst_count' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 0.36\n",
      "DDoS-UDP_Flood: Mean = 0.28\n",
      "DDoS-TCP_Flood: Mean = 0.11\n",
      "DDoS-PSHACK_Flood: Mean = 1.10\n",
      "DDoS-RSTFINFlood: Mean = 0.46\n",
      "DDoS-SYN_Flood: Mean = 0.17\n",
      "DDoS-SynonymousIP_Flood: Mean = 0.14\n",
      "DoS-UDP_Flood: Mean = 0.70\n",
      "DoS-TCP_Flood: Mean = 1.69\n",
      "DoS-SYN_Flood: Mean = 0.62\n",
      "\n",
      "Statistics for 'flow_duration' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 0.02\n",
      "DDoS-UDP_Flood: Mean = 0.61\n",
      "DDoS-TCP_Flood: Mean = 0.63\n",
      "DDoS-PSHACK_Flood: Mean = 0.59\n",
      "DDoS-RSTFINFlood: Mean = 0.07\n",
      "DDoS-SYN_Flood: Mean = 0.16\n",
      "DDoS-SynonymousIP_Flood: Mean = 1.47\n",
      "DoS-UDP_Flood: Mean = 0.33\n",
      "DoS-TCP_Flood: Mean = 2.60\n",
      "DoS-SYN_Flood: Mean = 3.22\n",
      "\n",
      "Statistics for 'Tot size' across the top 10 labels:\n",
      "DDoS-ICMP_Flood: Mean = 42.89\n",
      "DDoS-UDP_Flood: Mean = 50.90\n",
      "DDoS-TCP_Flood: Mean = 57.12\n",
      "DDoS-PSHACK_Flood: Mean = 54.48\n",
      "DDoS-RSTFINFlood: Mean = 54.95\n",
      "DDoS-SYN_Flood: Mean = 56.44\n",
      "DDoS-SynonymousIP_Flood: Mean = 54.62\n",
      "DoS-UDP_Flood: Mean = 79.01\n",
      "DoS-TCP_Flood: Mean = 57.16\n",
      "DoS-SYN_Flood: Mean = 56.57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Step 2: Calculate variance for each numerical column and select the top 10\n",
    "top_variance_cols = df[numerical_cols].var().nlargest(10).index.tolist()\n",
    "\n",
    "# Step 3: Print the top 10 columns with the highest numeric variance\n",
    "print(\"Top 10 Columns with Highest Numeric Variance:\")\n",
    "print(\", \".join(top_variance_cols))\n",
    "\n",
    "# Step 4: Print mean, median, max, min, and standard deviation for each column across the top 10 labels\n",
    "top_labels = df['label'].value_counts().nlargest(10).index.tolist()\n",
    "\n",
    "result_data = {}\n",
    "\n",
    "for col in top_variance_cols:\n",
    "    result_data[col] = {}  # Initialize an empty dictionary for each column\n",
    "    print(f\"\\nStatistics for '{col}' across the top 10 labels:\")\n",
    "    for label in top_labels:\n",
    "        values = df[df['label'] == label][col]\n",
    "        # print(f\"{label}: Mean = {values.mean():.2f}, Median = {values.median():.2f}, Max = {values.max():.2f}, Min = {values.min():.2f}, Std Dev = {values.std():.2f}\")\n",
    "        print(f\"{label}: Mean = {values.mean():.2f}\")\n",
    "        result_data[col][label] = values.mean()\n",
    "\n",
    "result_json = pd.DataFrame(result_data)\n",
    "result_json.to_json(\"mean_data.json\", orient=\"index\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns with Highest Numeric Variance (excluding 'IAT'):\n",
      "Header_Length, Covariance, Rate, Srate, Max, rst_count, flow_duration, Tot size, AVG, Radius\n",
      "\n",
      "Rescaled Data:\n",
      "   Header_Length  Covariance       Rate      Srate       Max  rst_count  \\\n",
      "0       7.378044         0.0   0.175378   0.175378  3.600576        0.0   \n",
      "1       5.589427         0.0   3.975653   3.975653  3.600576        0.0   \n",
      "2       5.589427         0.0  26.670390  26.670390  3.600576        0.0   \n",
      "3      15.370925         0.0   0.531695   0.531695  3.600576        0.0   \n",
      "4       0.221507         0.0   6.076157   6.076157  9.805569        0.0   \n",
      "\n",
      "   flow_duration  Tot size       AVG  Radius  \n",
      "0            0.0  2.425271  2.398946     0.0  \n",
      "1            0.0  2.425271  2.398946     0.0  \n",
      "2            0.0  2.425271  2.398946     0.0  \n",
      "3            0.0  2.425271  2.398946     0.0  \n",
      "4            0.0  0.347622  0.893230     0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Remove \"IAT\" and \"Tot sum\" from the list of numerical columns\n",
    "numerical_cols = [col for col in numerical_cols if col not in [\"IAT\", \"Tot sum\"]]\n",
    "\n",
    "# Step 2: Calculate variance for each numerical column (excluding \"IAT\") and select the top 10\n",
    "top_variance_cols = df[numerical_cols].var().nlargest(10).index.tolist()\n",
    "\n",
    "# Step 3: Print the top 10 columns with the highest numeric variance\n",
    "print(\"Top 10 Columns with Highest Numeric Variance (excluding 'IAT'):\")\n",
    "print(\", \".join(top_variance_cols))\n",
    "\n",
    "# Step 4: Print mean, median, max, min, and standard deviation for each column across the top 10 labels\n",
    "top_labels = df['label'].value_counts().nlargest(10).index.tolist()\n",
    "\n",
    "normalized_data = pd.DataFrame()\n",
    "\n",
    "# Calculate the dynamic rescale factor for each column\n",
    "# rescale_factors = {col: 10 ** (int(np.log10(df[col].max())) - 1) for col in top_variance_cols}\n",
    "rescale_factors = {col: 10 ** (int(np.log10(df[col].max()))) for col in top_variance_cols}\n",
    "\n",
    "for col in top_variance_cols:\n",
    "    # Normalize the data between 0 and 1\n",
    "    normalized_data[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    # Rescale the normalized data based on the dynamic factor\n",
    "    normalized_data[col] *= rescale_factors[col]\n",
    "\n",
    "    # Filter out values that are significantly larger than the mean of the column\n",
    "    threshold = 10 * normalized_data[col].median()\n",
    "    normalized_data[col] = np.where(normalized_data[col] > threshold, threshold, normalized_data[col])\n",
    "\n",
    "# Print normalized data for verification\n",
    "print(\"\\nRescaled Data:\")\n",
    "print(normalized_data.head())\n",
    "\n",
    "# Save the normalized data to a JSON file\n",
    "normalized_data.to_json(\"spider-plot_normalized_data.json\", orient=\"index\", indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
